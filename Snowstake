import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tkinter as tk
from tkinter import filedialog, ttk
from PIL import Image, ImageTk
import pandas as pd
from datetime import datetime
import re
import traceback

def create_gui():
    """
    Create a simple tkinter GUI for testing the stake detection algorithm.
    """
    def select_image():
        path = filedialog.askopenfilename(filetypes=[("Image files", "*.jpg;*.jpeg;*.png")])
        if not path:
            return
        
        # Get the visibility threshold from the slider
        vis_threshold = float(visibility_threshold_var.get())
        process_image(path, vis_threshold)
    
    def select_directory():
        dir_path = filedialog.askdirectory()
        if not dir_path:
            return
        
        # Get the visibility threshold from the slider
        vis_threshold = float(visibility_threshold_var.get())
        
        output_dir = Path(dir_path) / "results"
        results = process_multiple_images(dir_path, str(output_dir), vis_threshold, export_excel=True)
        
        # Update the results text
        results_text.delete(1.0, tk.END)
        
        # Group results by visibility
        low_vis_images = []
        processed_images = []
        
        for img_name, stakes, snow_depths, is_low_visibility, whiteness_score in results:
            if is_low_visibility:
                low_vis_images.append((img_name, whiteness_score))
            else:
                processed_images.append((img_name, len(stakes), snow_depths))
        
        # Display summary
        results_text.insert(tk.END, f"Processed {len(results)} images\n")
        results_text.insert(tk.END, f"Low visibility images: {len(low_vis_images)}\n")
        results_text.insert(tk.END, f"Successfully analyzed images: {len(processed_images)}\n\n")
        
        # Excel export info
        excel_path = output_dir / "snow_depth_measurements.xlsx"
        if excel_path.exists():
            results_text.insert(tk.END, f"Excel report saved to: {excel_path}\n\n")
        
        # Display low visibility images
        if low_vis_images:
            results_text.insert(tk.END, "Low Visibility Images (Skipped Analysis):\n")
            for img_name, whiteness_score in low_vis_images:
                results_text.insert(tk.END, f"  {img_name} - Whiteness score: {whiteness_score:.2f}\n")
            results_text.insert(tk.END, "\n")
        
        # Display processed images
        if processed_images:
            results_text.insert(tk.END, "Analyzed Images:\n")
            for img_name, stake_count, snow_depths in processed_images:
                avg_depth = sum(snow_depths) / len(snow_depths) if snow_depths else "N/A"
                if isinstance(avg_depth, float):
                    avg_depth = f"{avg_depth:.1f} cm"
                results_text.insert(tk.END, f"  {img_name} - Stakes: {stake_count}, Avg Snow Depth: {avg_depth}\n")
    
    def process_image(path, visibility_threshold=0.85):
        try:
            orig, result, stakes, snow_depths, is_low_visibility, whiteness_score = detect_red_black_stakes(
                path, visibility_threshold=visibility_threshold)
            
            # Store these globally for potential export
            global orig_img_global, stakes_global, snow_depths_global, is_low_visibility_global, whiteness_score_global, bands_global
            orig_img_global = orig
            stakes_global = stakes
            snow_depths_global = snow_depths
            is_low_visibility_global = is_low_visibility
            whiteness_score_global = whiteness_score
            bands_global = bands if 'bands' in locals() else []
            
            # Convert images for display
            orig_pil = Image.fromarray(orig)
            result_pil = Image.fromarray(result)
            
            # Resize if needed
            max_width = 500
            ratio = max_width / orig_pil.width
            new_size = (max_width, int(orig_pil.height * ratio))
            
            orig_pil = orig_pil.resize(new_size)
            result_pil = result_pil.resize(new_size)
            
            # Update images
            orig_img = ImageTk.PhotoImage(orig_pil)
            result_img = ImageTk.PhotoImage(result_pil)
            
            orig_label.config(image=orig_img)
            orig_label.image = orig_img
            
            result_label.config(image=result_img)
            result_label.image = result_img
            
            # Update info
            if is_low_visibility:
                info_label.config(text=f"Low Visibility Image (Whiteness: {whiteness_score:.2f})")
            else:
                if stakes:
                    info_label.config(text=f"Stake detected" + (f", Snow Depth: {snow_depths[0]:.1f} cm" if snow_depths else ""))
                else:
                    info_label.config(text="No stake detected - try adjusting parameters")
            
            # Update the results text
            results_text.delete(1.0, tk.END)
            
            if is_low_visibility:
                results_text.insert(tk.END, "Image has low visibility due to fog or heavy precipitation.\n")
                results_text.insert(tk.END, f"Whiteness score: {whiteness_score:.2f} (Threshold: {visibility_threshold})\n")
                results_text.insert(tk.END, "Analysis skipped to avoid unreliable measurements.\n")
            elif not stakes:
                results_text.insert(tk.END, "No stake detected in the image.\n")
                results_text.insert(tk.END, "Suggestions:\n")
                results_text.insert(tk.END, "- Try adjusting the visibility threshold\n")
                results_text.insert(tk.END, "- Check that the image contains a red and black stake\n")
                results_text.insert(tk.END, "- Ensure the image has good lighting and contrast\n")
            else:
                x, y, w, h = stakes[0]
                snow_depth_text = f", Snow depth: {snow_depths[0]:.1f} cm" if snow_depths else ""
                results_text.insert(tk.END, f"Stake detected: x={x}, y={y}, width={w}, height={h}{snow_depth_text}\n")
                
                # Add band information if available
                if bands_global:
                    results_text.insert(tk.END, "\nBands detected (from top to bottom):\n")
                    for i, (color, start_y, end_y) in enumerate(bands_global):
                        results_text.insert(tk.END, f"{i+1}: {color.upper()} band, height: {end_y-start_y} pixels\n")
                
                # Add calculation explanation
                if snow_depths:
                    results_text.insert(tk.END, f"\nSnow Depth Calculation:\n")
                    results_text.insert(tk.END, f"- Stake total height: 150 cm\n")
                    visible_height = 150 - snow_depths[0]
                    results_text.insert(tk.END, f"- Visible portion: {visible_height:.1f} cm\n")
                    results_text.insert(tk.END, f"- Snow depth: 150 - {visible_height:.1f} = {snow_depths[0]:.1f} cm\n")
                
        except Exception as e:
            info_label.config(text=f"Error: {str(e)}")
            # Show detailed error for debugging
            results_text.delete(1.0, tk.END)
            results_text.insert(tk.END, traceback.format_exc())

    # Create the main window
    root = tk.Tk()
    root.title("Snow Depth Measurement Tool")
    root.geometry("1200x800")  # Larger window for better visualization
    
    # Create frames
    top_frame = ttk.Frame(root, padding=10)
    top_frame.pack(fill=tk.X)
    
    # Add visibility threshold slider
    visibility_frame = ttk.LabelFrame(top_frame, text="Low Visibility Detection", padding=10)
    visibility_frame.pack(side=tk.RIGHT, fill=tk.X, expand=True)
    
    visibility_threshold_var = tk.StringVar(value="0.85")
    ttk.Label(visibility_frame, text="Whiteness Threshold:").pack(side=tk.LEFT)
    threshold_slider = ttk.Scale(
        visibility_frame, 
        from_=0.5, 
        to=0.95, 
        orient=tk.HORIZONTAL, 
        length=200,
        variable=visibility_threshold_var
    )
    threshold_slider.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)
    threshold_slider.set(0.85)
    
    # Display the current value
    threshold_label = ttk.Label(visibility_frame, textvariable=visibility_threshold_var)
    threshold_label.pack(side=tk.LEFT, padx=5)
    
    # Update the label when the slider changes
    def update_threshold_label(*args):
        threshold_label.config(text=f"{float(visibility_threshold_var.get()):.2f}")
    
    threshold_slider.config(command=lambda v: visibility_threshold_var.set(f"{float(v):.2f}"))
    
    # Add buttons to top frame
    button_frame = ttk.Frame(top_frame, padding=10)
    button_frame.pack(side=tk.LEFT, fill=tk.X)
    
    ttk.Button(button_frame, text="Select Single Image", command=select_image).pack(side=tk.LEFT, padx=5)
    ttk.Button(button_frame, text="Process Directory", command=select_directory).pack(side=tk.LEFT, padx=5)
    
    # Add Excel export button for single image
    def export_single_image_results():
        # Check if we have processed an image
        if 'orig_img_global' not in globals() or 'stakes_global' not in globals() or 'snow_depths_global' not in globals():
            info_label.config(text="No image processed yet. Please select an image first.")
            return
            
        file_path = filedialog.asksaveasfilename(
            defaultextension=".xlsx",
            filetypes=[("Excel files", "*.xlsx"), ("All files", "*.*")],
            initialfile="snow_depth_measurement.xlsx"
        )
        if not file_path:
            return
            
        # Create results data in the same format as process_multiple_images
        img_name = "single_image.jpg"  # Default name for single image
        
        results = [(img_name, stakes_global, snow_depths_global, is_low_visibility_global, whiteness_score_global)]
        
        if export_to_excel(results, file_path):
            info_label.config(text=f"Results exported to {file_path}")
        else:
            info_label.config(text="Failed to export results")
            
    ttk.Button(button_frame, text="Export Current to Excel", command=export_single_image_results).pack(side=tk.LEFT, padx=5)
    
    image_frame = ttk.Frame(root, padding=10)
    image_frame.pack(fill=tk.BOTH, expand=True)
    
    info_frame = ttk.Frame(root, padding=10)
    info_frame.pack(fill=tk.X)
    
    # Add image labels to image frame
    orig_label = ttk.Label(image_frame)
    orig_label.pack(side=tk.LEFT, padx=5)
    
    result_label = ttk.Label(image_frame)
    result_label.pack(side=tk.LEFT, padx=5)
    
    # Add info label
    info_label = ttk.Label(info_frame, text="Select an image to begin")
    info_label.pack(anchor=tk.W)
    
    # Create a section to explain the snow depth calculation
    explanation_frame = ttk.LabelFrame(info_frame, text="Measurement Information", padding=10)
    explanation_frame.pack(fill=tk.X, pady=5)
    
    explanation_text = tk.Text(explanation_frame, height=5, width=60, wrap=tk.WORD)
    explanation_text.insert(tk.END, 
        "Snow Depth Calculation:\n"
        "• The stake is 150cm tall with alternating 10cm red and black bands\n"
        "• Top of stake has a small red section, followed by a black band\n"
        "• Snow depth = 150cm - visible length of the stake\n"
        "• Band detection may need adjustment for different lighting conditions"
    )
    explanation_text.config(state=tk.DISABLED)
    explanation_text.pack(fill=tk.X)
    
    # Add results text area
    results_frame = ttk.LabelFrame(info_frame, text="Detection Results", padding=10)
    results_frame.pack(fill=tk.BOTH, expand=True, pady=5)
    
    results_text = tk.Text(results_frame, height=8, width=60)
    results_text.pack(fill=tk.BOTH, expand=True)
    
    root.mainloop()

def is_low_visibility_image(img, threshold=0.85):
    """
    Determines if an image has low visibility due to fog, heavy snow, etc.
    
    Args:
        img: Input image (BGR format)
        threshold: Whiteness threshold (0-1). Higher means more sensitive to white.
        
    Returns:
        bool: True if the image has low visibility, False otherwise
        float: Whiteness score of the image (0-1)
    """
    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Calculate the average brightness
    avg_brightness = np.mean(gray) / 255.0
    
    # Calculate histogram to check for concentration in bright areas
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    hist = hist.flatten() / hist.sum()  # Normalize
    
    # Calculate the weighted sum (more weight to brighter pixels)
    bright_weight = np.sum(hist[200:] * np.arange(200, 256) / 255.0)
    
    # Calculate a "whiteness score" combining brightness and concentration
    whiteness_score = (avg_brightness * 0.6) + (bright_weight * 0.4)
    
    # Check variance - low variance is another indicator of fog/snow
    variance = np.var(gray) / (255.0 * 255.0)
    low_variance = variance < 0.05
    
    # Image is low visibility if it's very white and has low variance
    is_low_vis = (whiteness_score > threshold) or (whiteness_score > 0.75 and low_variance)
    
    return is_low_vis, whiteness_score


def detect_red_black_stakes(image_path, output_dir=None, visibility_threshold=0.85):
    """
    Detect a single red and black stake in an image with trees in foreground and background.
    Calculates snow depth based on the visible portion of the stake.
    
    The stake has the following properties:
    - Total height: 150 cm
    - Alternating red and black bands of 10 cm each
    - Small red section at the very top, followed by a black band
    - The red color is approximately #ff4276, but may vary with lighting
    
    Args:
        image_path (str): Path to the input image
        output_dir (str, optional): Directory to save output images. If None, images are displayed only.
        visibility_threshold (float): Threshold for detecting low visibility conditions (0-1)
        
    Returns:
        tuple: (Original image, processed image with stakes highlighted, stakes list, snow depth measurements, 
               is_low_visibility flag, whiteness score)
    """
    # Read the image
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"Could not read image at {image_path}")
    
    # Check for low visibility conditions
    is_low_visibility, whiteness_score = is_low_visibility_image(img, visibility_threshold)
    
    # Convert from BGR to RGB for display purposes
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Create a copy for visualization
    result_img = img_rgb.copy()
    
    # If low visibility, annotate the image and return early
    if is_low_visibility:
        cv2.putText(result_img, f"Low Visibility Detected: {whiteness_score:.2f}", 
                   (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 0, 0), 3)
        cv2.putText(result_img, "Fog or Heavy Precipitation", 
                   (30, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 0, 0), 3)
        cv2.putText(result_img, "Unable to reliably detect stakes", 
                   (30, 180), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 0, 0), 3)
        
        # If output directory is specified, save the image
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True, parents=True)
            base_name = Path(image_path).stem
            
            plt.figure(figsize=(12, 12))
            plt.imshow(result_img)
            plt.title("Low Visibility - Analysis Skipped")
            plt.axis('off')
            plt.tight_layout()
            plt.savefig(output_dir / f"{base_name}_low_visibility.jpg")
            plt.close()
            
        return img_rgb, result_img, [], [], is_low_visibility, whiteness_score
    
    # Step 1: Increase contrast using CLAHE (Contrast Limited Adaptive Histogram Equalization)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    enhanced_lab = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    
    # Step 2: Convert to different color spaces for better color detection
    hsv = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2HSV)
    
    # The target red color #ff4276 in BGR format is approximately (118, 66, 255)
    # Let's create a mask specifically targeting this red color with a tolerance range
    
    # For HSV: Convert target RGB color to HSV
    target_rgb = np.uint8([[[0x42, 0x76, 0xff]]])  # BGR order for OpenCV
    target_hsv = cv2.cvtColor(target_rgb, cv2.COLOR_BGR2HSV)
    target_h = target_hsv[0][0][0]  # Extract the Hue value
    
    # Define a broader range around the target hue to account for lighting variation
    # Red is tricky in HSV since it wraps around 0/180 in OpenCV's representation
    hue_tolerance = 15
    sat_min = 100
    val_min = 100
    
    # Create red masks around the target color
    if target_h - hue_tolerance < 0:
        # If the range wraps around 0, we need two masks
        lower_red1 = np.array([0, sat_min, val_min])
        upper_red1 = np.array([target_h + hue_tolerance, 255, 255])
        lower_red2 = np.array([180 + (target_h - hue_tolerance), sat_min, val_min])
        upper_red2 = np.array([180, 255, 255])
    elif target_h + hue_tolerance > 180:
        # If the range wraps around 180, we need two masks
        lower_red1 = np.array([0, sat_min, val_min])
        upper_red1 = np.array([(target_h + hue_tolerance) - 180, 255, 255])
        lower_red2 = np.array([target_h - hue_tolerance, sat_min, val_min])
        upper_red2 = np.array([180, 255, 255])
    else:
        # Standard case - no wrapping
        lower_red1 = np.array([max(0, target_h - hue_tolerance), sat_min, val_min])
        upper_red1 = np.array([min(180, target_h + hue_tolerance), 255, 255])
        lower_red2 = np.array([0, 0, 0])  # Dummy values
        upper_red2 = np.array([0, 0, 0])  # Dummy values
    
    # Also try in RGB space using a direct color distance approach
    img_rgb_cv = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
    target_rgb_direct = np.array([0xff, 0x42, 0x76])  # RGB format
    rgb_distance = np.sqrt(np.sum((img_rgb_cv.astype(np.float32) - target_rgb_direct) ** 2, axis=2))
    rgb_mask = (rgb_distance < 80).astype(np.uint8) * 255
    
    # Combine multiple color detection approaches
    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    if lower_red2[0] != 0 or upper_red2[0] != 0:  # If we have a valid second range
        red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        red_mask_hsv = cv2.bitwise_or(red_mask1, red_mask2)
    else:
        red_mask_hsv = red_mask1
    
    # Combine HSV and RGB masks
    red_mask = cv2.bitwise_or(red_mask_hsv, rgb_mask)
    
    # Apply morphological operations to enhance the mask
    kernel = np.ones((5, 5), np.uint8)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # Find contours in the red mask
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Filter contours to find the most likely stake
    stake_candidates = []
    min_area = 200  # Minimum area to be considered a stake component
    min_ratio = 1.5  # Minimum height/width ratio to identify vertical stakes
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > min_area:
            x, y, w, h = cv2.boundingRect(contour)
            ratio = h / w if w > 0 else 0
            if ratio > min_ratio:  # Looking for vertical structures
                stake_candidates.append((contour, x, y, w, h, area, ratio))
    
    # Sort candidates by area (larger is more likely to be the stake)
    stake_candidates.sort(key=lambda x: x[5], reverse=True)
    
    # If no candidates found, try with less strict criteria
    if not stake_candidates:
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > min_area / 2:  # Lower the area threshold
                x, y, w, h = cv2.boundingRect(contour)
                ratio = h / w if w > 0 else 0
                if ratio > min_ratio / 1.5:  # Lower the ratio threshold
                    stake_candidates.append((contour, x, y, w, h, area, ratio))
        
        stake_candidates.sort(key=lambda x: x[5], reverse=True)
    
    # Initialize lists
    stakes = []
    snow_depths = []
    bands = []  # Make bands available globally
    
    # Process the most likely candidate if found
    if stake_candidates:
        # Take the largest area candidate
        _, x, y, w, h = stake_candidates[0][:5]
        stakes.append((x, y, w, h))
        
        # For visualization, add a diagnostic image of the red mask
        mask_rgb = cv2.cvtColor(red_mask, cv2.COLOR_GRAY2RGB)
        mask_height, mask_width = red_mask.shape[:2]
        result_height, result_width = result_img.shape[:2]
        
        # Position the mask in the top-right corner (if it fits)
        mask_display_width = min(250, mask_width)
        mask_display_height = int((mask_display_width / mask_width) * mask_height)
        mask_resized = cv2.resize(mask_rgb, (mask_display_width, mask_display_height))
        
        if mask_display_width < result_width and mask_display_height < result_height:
            result_img[10:10+mask_display_height, result_width-mask_display_width-10:result_width-10] = mask_resized
            
        # Draw text to indicate this is the red mask
        cv2.putText(result_img, "Red Mask", (result_width-mask_display_width-10, 8), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Extract the stake region
        stake_roi = enhanced_img[y:y+h, x:x+w]
        
        # Calculate snow depth
        # We need to analyze the red and black bands
        
        # Convert ROI to HSV for color analysis
        stake_hsv = cv2.cvtColor(stake_roi, cv2.COLOR_BGR2HSV)
        
        # Create masks for red within the stake region
        red_stake_mask1 = cv2.inRange(stake_hsv, lower_red1, upper_red1)
        if lower_red2[0] != 0 or upper_red2[0] != 0:
            red_stake_mask2 = cv2.inRange(stake_hsv, lower_red2, upper_red2)
            red_stake_mask = cv2.bitwise_or(red_stake_mask1, red_stake_mask2)
        else:
            red_stake_mask = red_stake_mask1
        
        # For black, use a simple threshold on value channel
        _, black_stake_mask = cv2.threshold(stake_hsv[:,:,2], 50, 255, cv2.THRESH_BINARY_INV)
        
        # Analyze vertical profile of colors to identify bands
        red_profile = np.sum(red_stake_mask, axis=1) / w  # Average red intensity at each y-coordinate
        black_profile = np.sum(black_stake_mask, axis=1) / w  # Average black intensity at each y-coordinate
        
        # Smooth the profiles to reduce noise
        kernel_size = max(3, int(h / 30))
        if kernel_size % 2 == 0:
            kernel_size += 1  # Ensure odd kernel size
            
        red_profile_smooth = cv2.GaussianBlur(red_profile.reshape(-1, 1), (1, kernel_size), 0).flatten()
        black_profile_smooth = cv2.GaussianBlur(black_profile.reshape(-1, 1), (1, kernel_size), 0).flatten()
        
        # Identify bands by analyzing the smoothed profiles
        # Start from the top (minimum y) and move down
        bands = []
        current_y = 0
        band_height_pixels = h / 15  # Approximate pixel height for 10cm band (15 bands total for 150cm)
        
        while current_y < h:
            # Check window of approximate band height
            end_y = min(h, int(current_y + band_height_pixels))
            window_red = red_profile_smooth[current_y:end_y]
            window_black = black_profile_smooth[current_y:end_y]
            
            # Determine if this section is more red or black
            if np.mean(window_red) > np.mean(window_black):
                bands.append(('red', current_y, end_y))
            else:
                bands.append(('black', current_y, end_y))
                
            current_y = end_y
        
        # Calculate approximate scale (pixels per cm)
        px_per_cm = h / 150
        
        # Determine snow depth based on the pattern of visible bands
        visible_bands = len(bands)
        
        if visible_bands > 0:
            # Check if the first band is red (expected)
            if bands[0][0] == 'red':
                # Count how many full 10cm bands are visible
                visible_height_cm = 0
                
                for i, (color, start_y, end_y) in enumerate(bands):
                    band_height_px = end_y - start_y
                    band_height_cm = band_height_px / px_per_cm
                    
                    # First (red) band might be partially visible
                    if i == 0:
                        visible_height_cm += min(band_height_cm, 5)  # Top red section is about 5cm
                    else:
                        visible_height_cm += min(band_height_cm, 10)  # Regular bands are 10cm
            else:
                # If the first visible band is black, we've lost the top red section
                visible_height_cm = 5  # Start counting from 5cm mark (after the top red section)
                
                for i, (color, start_y, end_y) in enumerate(bands):
                    band_height_px = end_y - start_y
                    band_height_cm = band_height_px / px_per_cm
                    visible_height_cm += min(band_height_cm, 10)  # Regular bands are 10cm
            
            # Snow depth is the height from top of stake minus visible portion
            snow_depth_cm = 150 - visible_height_cm
            snow_depths.append(snow_depth_cm)
            
            # Draw stake and snow depth on the image
            cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 3)
            cv2.putText(result_img, f"Stake", (x, y - 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            cv2.putText(result_img, f"Snow: {snow_depth_cm:.1f} cm", (x, y - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # Draw band analysis visualization
            band_viz = np.zeros((h, 50, 3), dtype=np.uint8)
            for color, start_y, end_y in bands:
                band_color = (0, 0, 255) if color == 'red' else (0, 0, 0)  # BGR format
                cv2.rectangle(band_viz, (0, start_y), (50, end_y), band_color, -1)
            
            # Add band visualization next to the stake
            viz_x = x + w + 10
            viz_end_x = viz_x + 50
            
            # Make sure visualization fits in the image
            if viz_end_x < result_img.shape[1]:
                result_img[y:y+h, viz_x:viz_end_x] = band_viz
        else:
            # No bands detected, just draw the bounding box
            cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 3)
            cv2.putText(result_img, "Stake (bands not detected)", (x, y - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    else:
        # No stake found, add message to image
        cv2.putText(result_img, "No stake detected", (30, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 0, 0), 3)
        cv2.putText(result_img, "Try adjusting detection parameters", (30, 100), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)
    
    # Save or display results
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True, parents=True)
        
        base_name = Path(image_path).stem
        
        # Save main result
        plt.figure(figsize=(12, 12))
        plt.imshow(result_img)
        plt.title("Detected Stakes and Snow Depth" if not is_low_visibility else "Low Visibility - Analysis Limited")
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_dir / f"{base_name}_detected_stakes.jpg")
        
        if not is_low_visibility:
            # Save intermediate processing steps
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            axes = axes.flatten()
            
            axes[0].imshow(img_rgb)
            axes[0].set_title("Original Image")
            axes[0].axis('off')
            
            axes[1].imshow(cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB))
            axes[1].set_title("Enhanced Contrast")
            axes[1].axis('off')
            
            axes[2].imshow(red_mask, cmap='gray')
            axes[2].set_title("Red Mask")
            axes[2].axis('off')
            
            axes[3].imshow(black_stake_mask if 'black_stake_mask' in locals() else np.zeros_like(red_mask), cmap='gray')
            axes[3].set_title("Black Mask (Stake Region)" if 'black_stake_mask' in locals() else "Black Mask (Not Available)")
            axes[3].axis('off')
            
            plt.tight_layout()
            plt.savefig(output_dir / f"{base_name}_processing_steps.jpg")
        
        plt.close('all')
        
        print(f"Results saved to {output_dir}")
    else:
        # Display the original and result images
        plt.figure(figsize=(15, 10))
        
        plt.subplot(1, 2, 1)
        plt.imshow(img_rgb)
        plt.title("Original Image")
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(result_img)
        plt.title("Detected Stakes and Snow Depth" if not is_low_visibility else "Low Visibility - Analysis Limited")
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()
    
    return img_rgb, result_img, stakes, snow_depths, is_low_visibility, whiteness_score


def export_to_excel(results, output_path):
    """
    Export snow depth measurements to an Excel file.
    
    Args:
        results: List of tuples containing (image_name, stakes, snow_depths, is_low_visibility, whiteness_score)
        output_path: Path to save the Excel file
    """
    try:
        # Create data for the Excel file
        data = []
        
        for img_name, stakes, snow_depths, is_low_visibility, whiteness_score in results:
            # Try to extract date from filename (assuming format like YYYY-MM-DD or similar)
            date_str = None
            date_match = re.search(r'(\d{4}[-_/]?\d{1,2}[-_/]?\d{1,2})', img_name)
            if date_match:
                date_str = date_match.group(1)
            
            if is_low_visibility:
                data.append({
                    'Image Name': img_name,
                    'Date': date_str,
                    'Status': 'Low Visibility',
                    'Whiteness Score': f"{whiteness_score:.2f}",
                    'Stakes Detected': 0,
                    'Snow Depth (cm)': None,
                    'Notes': 'Excluded due to fog/precipitation'
                })
            else:
                # If no stakes were detected
                if not snow_depths:
                    data.append({
                        'Image Name': img_name,
                        'Date': date_str,
                        'Status': 'Processed',
                        'Whiteness Score': f"{whiteness_score:.2f}",
                        'Stakes Detected': 0,
                        'Snow Depth (cm)': None,
                        'Notes': 'No stakes detected'
                    })
                else:
                    # For each stake in the image
                    for i, depth in enumerate(snow_depths):
                        data.append({
                            'Image Name': img_name,
                            'Date': date_str,
                            'Status': 'Processed',
                            'Whiteness Score': f"{whiteness_score:.2f}",
                            'Stakes Detected': len(snow_depths),
                            'Stake Number': i + 1,
                            'Snow Depth (cm)': f"{depth:.1f}",
                            'Notes': ''
                        })
        
        # Create DataFrame
        df = pd.DataFrame(data)
        
        # Add summary statistics
        total_images = len(results)
        low_vis_images = sum(1 for _, _, _, is_low_vis, _ in results if is_low_vis)
        processed_images = total_images - low_vis_images
        
        valid_depths = [depth for _, _, depths, is_low_vis, _ in results 
                       for depth in depths if not is_low_vis]
        
        avg_depth = sum(valid_depths) / len(valid_depths) if valid_depths else None
        min_depth = min(valid_depths) if valid_depths else None
        max_depth = max(valid_depths) if valid_depths else None
        
        # Create a summary DataFrame
        summary_data = [
            {'Metric': 'Total Images', 'Value': total_images},
            {'Metric': 'Low Visibility Images', 'Value': low_vis_images},
            {'Metric': 'Processed Images', 'Value': processed_images},
            {'Metric': 'Average Snow Depth (cm)', 'Value': f"{avg_depth:.1f}" if avg_depth is not None else 'N/A'},
            {'Metric': 'Minimum Snow Depth (cm)', 'Value': f"{min_depth:.1f}" if min_depth is not None else 'N/A'},
            {'Metric': 'Maximum Snow Depth (cm)', 'Value': f"{max_depth:.1f}" if max_depth is not None else 'N/A'},
            {'Metric': 'Processing Date', 'Value': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
        ]
        summary_df = pd.DataFrame(summary_data)
        
        # Create Excel writer
        with pd.ExcelWriter(output_path) as writer:
            df.to_excel(writer, sheet_name='Snow Depth Measurements', index=False)
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
            
            # Auto-adjust columns' width
            for sheet in writer.sheets:
                worksheet = writer.sheets[sheet]
                for i, col in enumerate(df.columns if sheet == 'Snow Depth Measurements' else summary_df.columns):
                    column_len = max(df[col].astype(str).map(len).max() if sheet == 'Snow Depth Measurements' else 
                                    summary_df[col].astype(str).map(len).max(), 
                                    len(col)) + 2
                    worksheet.set_column(i, i, column_len)
                    
        print(f"Excel report saved to {output_path}")
        return True
    except Exception as e:
        print(f"Error exporting to Excel: {e}")
        traceback.print_exc()
        return False


def process_multiple_images(image_dir, output_dir=None, visibility_threshold=0.85, export_excel=True):
    """
    Process all images in a directory to detect stakes and measure snow depth.
    
    Args:
        image_dir (str): Directory containing images
        output_dir (str, optional): Directory to save results
        visibility_threshold (float): Threshold for detecting low visibility conditions (0-1)
        export_excel (bool): Whether to export results to an Excel file
        
    Returns:
        list: List of tuples containing (image_name, stakes, snow_depths, is_low_visibility, whiteness_score)
    """
    image_dir = Path(image_dir)
    image_paths = list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png"))
    
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True, parents=True)
    
    results = []
    for img_path in image_paths:
        print(f"Processing {img_path.name}...")
        try:
            _, _, stakes, snow_depths, is_low_visibility, whiteness_score = detect_red_black_stakes(
                str(img_path), output_dir, visibility_threshold)
            results.append((img_path.name, stakes, snow_depths, is_low_visibility, whiteness_score))
        except Exception as e:
            print(f"Error processing {img_path.name}: {e}")
    
    # Export to Excel if requested
    if export_excel and output_dir and results:
        excel_path = output_dir / "snow_depth_measurements.xlsx"
        export_to_excel(results, excel_path)
    
    return results
if __name__ == "__main__":
    # Example usage:
    # 1. Process a single image:
    # detect_red_black_stakes("path/to/image.jpg", "path/to/output", visibility_threshold=0.85)
    
    # 2. Process multiple images:
    # process_multiple_images("path/to/images", "path/to/output", visibility_threshold=0.85, export_excel=True)
    
    # 3. Launch the GUI for interactive testing:
    create_gui()
